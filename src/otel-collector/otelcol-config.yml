# Copyright The OpenTelemetry Authors
# SPDX-License-Identifier: Apache-2.0

receivers:
  otlp:
    protocols:
      grpc:
        endpoint: ${env:OTEL_COLLECTOR_HOST}:${env:OTEL_COLLECTOR_PORT_GRPC}
      http:
        endpoint: ${env:OTEL_COLLECTOR_HOST}:${env:OTEL_COLLECTOR_PORT_HTTP}
        cors:
          allowed_origins:
            - "http://*"
            - "https://*"
  httpcheck/frontend-proxy:
    targets:
      - endpoint: http://${env:FRONTEND_PROXY_ADDR}
  nginx:
    endpoint: http://${env:IMAGE_PROVIDER_HOST}:${env:IMAGE_PROVIDER_PORT}/status
    collection_interval: 10s
  docker_stats:
    endpoint: unix:///var/run/docker.sock
    # https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/44511
    api_version: "1.44"
  postgresql:
    endpoint: ${POSTGRES_HOST}:${POSTGRES_PORT}
    username: root
    password: ${POSTGRES_PASSWORD}
    metrics:
      postgresql.blks_hit:
        enabled: true
      postgresql.blks_read:
        enabled: true
      postgresql.tup_fetched:
        enabled: true
      postgresql.tup_returned:
        enabled: true
      postgresql.tup_inserted:
        enabled: true
      postgresql.tup_updated:
        enabled: true
      postgresql.tup_deleted:
        enabled: true
      postgresql.deadlocks:
        enabled: true
    tls:
      insecure: true
  redis:
    endpoint: "valkey-cart:6379"
    username: "valkey"
    collection_interval: 10s
  # Host metrics
  hostmetrics:
    root_path: /hostfs
    scrapers:
      cpu:
        metrics:
          system.cpu.utilization:
            enabled: true
          system.cpu.logical.count:
            enabled: true
      disk:
      load:
      filesystem:
        exclude_mount_points:
          mount_points:
            - /dev/*
            - /proc/*
            - /sys/*
            - /run/k3s/containerd/*
            - /var/lib/docker/*
            - /var/lib/kubelet/*
            - /snap/*
          match_type: regexp
        exclude_fs_types:
          fs_types:
            - autofs
            - binfmt_misc
            - bpf
            - cgroup2
            - configfs
            - debugfs
            - devpts
            - devtmpfs
            - fusectl
            - hugetlbfs
            - iso9660
            - mqueue
            - nsfs
            - overlay
            - proc
            - procfs
            - pstore
            - rpc_pipefs
            - securityfs
            - selinuxfs
            - squashfs
            - sysfs
            - tracefs
          match_type: strict
      memory:
        metrics:
          system.memory.utilization:
            enabled: true
          system.memory.limit:
            enabled: true
      network:
      paging:
        metrics:
          system.paging.usage:
            enabled: true

      processes:
      process:
        mute_process_exe_error: true
        mute_process_io_error: true
        mute_process_user_error: true
      system:
        metrics:
          system.uptime:
            enabled: true
exporters:
  debug:
  otlp_grpc/jaeger:
    endpoint: "jaeger:4317"
    tls:
      insecure: true
    sending_queue:
      batch:
  otlp_http/prometheus:
    endpoint: "http://prometheus:9090/api/v1/otlp"
    tls:
      insecure: true
    sending_queue:
      batch:
  opensearch:
    logs_index: otel-logs
    logs_index_time_format: "yyyy-MM-dd"
    http:
      endpoint: "http://opensearch:9200"
      tls:
        insecure: true
    sending_queue:
      # Explicitly set due to bug: https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/45016
      num_consumers: 10
      queue_size: 1000
      batch:
processors:
  memory_limiter:
    check_interval: 5s
    limit_percentage: 80
    spike_limit_percentage: 25
  resourcedetection:
    detectors: [env, docker, system]
  resource/postgresql:
    attributes:
      - key: service.name
        value: postgresql
        action: upsert
  transform/postgresql:
    error_mode: ignore
    metric_statements:
      - context: resource
        statements:
          # Construct unique service.instance.id based on PostgreSQL resource scope.
          # The PostgreSQL receiver sets postgresql.database.name, postgresql.table.name,
          # postgresql.index.name as resource attributes, creating multiple target_info
          # entries with the same identifying labels. By including these in service.instance.id,
          # each scope gets a unique target_info, allowing info() to work correctly.
          - set(attributes["service.instance.id"], Concat([attributes["service.name"], "/", attributes["postgresql.database.name"], "/", attributes["postgresql.table.name"], "/", attributes["postgresql.index.name"]], "")) where attributes["postgresql.index.name"] != nil
          - set(attributes["service.instance.id"], Concat([attributes["service.name"], "/", attributes["postgresql.database.name"], "/", attributes["postgresql.table.name"]], "")) where attributes["postgresql.table.name"] != nil and attributes["postgresql.index.name"] == nil
          - set(attributes["service.instance.id"], Concat([attributes["service.name"], "/", attributes["postgresql.database.name"]], "")) where attributes["postgresql.database.name"] != nil and attributes["postgresql.table.name"] == nil
          - set(attributes["service.instance.id"], attributes["service.name"]) where attributes["postgresql.database.name"] == nil
  transform/sanitize_spans:
    error_mode: ignore
    trace_statements:
      - context: span
        statements:
          # Sanitize spans to prevent span metrics cardinality explosion
          # caused by non-compliant high cardinality span names:
          # 1. Define missing http.route on key HTTP operations for meaningful operation names
          # 2. Then normalize span names; http server spans lacking http.route default to operations "GET", "POST", etc.

          # FRONTEND SERVICE

          # Workaround for Next.js high cardinality span name issue: https://github.com/vercel/next.js/issues/54694
          - set(span.attributes["http.route"], "/api/cart") where
            span.kind == SPAN_KIND_SERVER and
            resource.attributes["service.name"] == "frontend" and
            span.attributes["http.route"] == nil and
            IsMatch(span.attributes["http.target"], "\\/api\\/cart")  # e.g. # /api/cart

          - set(span.attributes["http.route"], "/api/checkout") where
            span.kind == SPAN_KIND_SERVER and
            resource.attributes["service.name"] == "frontend" and
            span.attributes["http.route"] == nil and
            IsMatch(span.attributes["http.target"], "\\/api\\/checkout")  # e.g. # /api/checkout

          - set(span.attributes["http.route"], "/api/products/{productId}") where
            span.kind == SPAN_KIND_SERVER and
            resource.attributes["service.name"] == "frontend" and
            span.attributes["http.route"] == nil and
            IsMatch(span.attributes["http.target"], "\\/api\\/products\\/.*")  # e.g. /api/products/1YMWWN1N4O

          - set(span.attributes["http.route"], "/api/recommendations") where
            span.kind == SPAN_KIND_SERVER and
            resource.attributes["service.name"] == "frontend" and
            span.attributes["http.route"] == nil and
            IsMatch(span.attributes["http.target"], "\\/api\\/recommendations")  # e.g. # /api/recommendations?productIds=...

          - set(span.attributes["http.route"], "/api/data") where
            span.kind == SPAN_KIND_SERVER and
            resource.attributes["service.name"] == "frontend" and
            span.attributes["http.route"] == nil and
            IsMatch(span.attributes["http.target"], "\\/api\\/data.*")  # e.g. # " /api/data?contextKeys=telescopes" or /api/data/?contextKeys=cameras

          # SANITIZE ALL SPAN NAMES TO PREVENT CARDINALITY EXPLOSION
          - set_semconv_span_name("1.37.0", "original_span_name")
    metric_statements:
      - context: resource
        statements:
          # Set service.instance.id to service.name if not already set (needed for Prometheus info() joins)
          - set(attributes["service.instance.id"], attributes["service.name"]) where attributes["service.instance.id"] == nil and attributes["service.name"] != nil

connectors:
  spanmetrics:

service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [resourcedetection, memory_limiter, transform/sanitize_spans]
      exporters: [otlp_grpc/jaeger, debug, spanmetrics]
    metrics:
      receivers: [docker_stats, httpcheck/frontend-proxy, hostmetrics, nginx, otlp, redis, spanmetrics]
      processors: [resourcedetection, transform/sanitize_spans, memory_limiter]
      exporters: [otlp_http/prometheus, debug]
    metrics/postgresql:
      receivers: [postgresql]
      processors: [resourcedetection, resource/postgresql, transform/postgresql, memory_limiter]
      exporters: [otlp_http/prometheus, debug]
    logs:
      receivers: [otlp]
      processors: [resourcedetection, memory_limiter]
      exporters: [opensearch, debug]
  telemetry:
    metrics:
      readers:
        - periodic:
            exporter:
              otlp:
                protocol: http/protobuf
                # replace with your observability meta monitoring backend
                endpoint: http://${env:OTEL_COLLECTOR_HOST}:${env:OTEL_COLLECTOR_PORT_HTTP}
    logs:
      processors:
        - batch:
            exporter:
              otlp:
                protocol: http/protobuf
                # replace with your observability meta monitoring backend
                endpoint: http://${env:OTEL_COLLECTOR_HOST}:${env:OTEL_COLLECTOR_PORT_HTTP}
