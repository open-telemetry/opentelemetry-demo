
# Copyright The OpenTelemetry Authors
# SPDX-License-Identifier: Apache-2.0
# This file is generated by 'make generate-kubernetes-manifests' and then updated for Splunk
---
apiVersion: v1
kind: Namespace
metadata:
  name: otel-demo
---
# Source: opentelemetry-demo/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: opentelemetry-demo
  labels:
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
---
# Source: opentelemetry-demo/templates/flagd-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: flagd-config
  #namespace: otel-demo
  labels:
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
data:  
  demo.flagd.json: |
    {
      "$schema": "https://flagd.dev/schema/v0/flags.json",
      "flags": {
        "productCatalogFailure": {
          "description": "Fail product catalog service on a specific product",
          "state": "ENABLED",
          "variants": {
            "on": true,
            "off": false
          },
          "defaultVariant": "off"
        },
        "recommendationCacheFailure": {
          "description": "Fail recommendation service cache",
          "state": "ENABLED",
          "variants": {
            "on": true,
            "off": false
          },
          "defaultVariant": "off"
        },
        "adManualGc": {
          "description": "Triggers full manual garbage collections in the ad service",
          "state": "ENABLED",
          "variants": {
            "on": true,
            "off": false
          },
          "defaultVariant": "off"
        },
        "adHighCpu": {
          "description": "Triggers high cpu load in the ad service",
          "state": "ENABLED",
          "variants": {
            "on": true,
            "off": false
          },
          "defaultVariant": "off"
        },
        "adFailure": {
          "description": "Fail ad service",
          "state": "ENABLED",
          "variants": {
            "on": true,
            "off": false
          },
          "defaultVariant": "off"
        },
        "kafkaQueueProblems": {
          "description": "Overloads Kafka queue while simultaneously introducing a consumer side delay leading to a lag spike",
          "state": "ENABLED",
          "variants": {
            "on": 100,
            "off": 0
          },
          "defaultVariant": "off"
        },
        "paymentRetryMax": {
          "description": "Maximum number of payment retry attempts",
          "state": "ENABLED",
          "variants": {
            "10": 10,
            "5": 5,
            "4": 4,
            "2": 2,
            "1": 1
          },
          "defaultVariant": "4"
        },
        "fraudDetectionEnabled": {
          "description": "Enable fraud detection analysis on orders",
          "state": "ENABLED",
          "variants": {
            "on": 1,
            "off": 0
          },
          "defaultVariant": "on"
        },
        "mutateFraudOrders": {
          "description": "Percentage of orders to mutate for fraud alerts (0-100%)",
          "state": "ENABLED",
          "variants": {
            "off": 0,
            "medium": 40,
            "high": 60,
            "veryhigh": 90
          },
          "defaultVariant": "off"
        },
        "executeBadQueries": {
          "description": "Percentage of orders that trigger bad database queries (0-100%)",
          "state": "ENABLED",
          "variants": {
            "off": 0,
            "low": 20,
            "medium": 40,
            "high": 60
          },
          "defaultVariant": "off"
        },
        "cartFailure": {
          "description": "Fail cart service",
          "state": "ENABLED",
          "variants": {
            "on": true,
            "off": false
          },
          "defaultVariant": "off"
        },
        "paymentFailure": {
          "description": "Fail payment service charge requests n%",
          "state": "ENABLED",
          "variants": {
            "100%": 1,
            "90%": 0.95,
            "75%": 0.75,
            "50%": 0.5,
            "25%": 0.25,
            "10%": 0.1,
            "off": 0
          },
          "defaultVariant": "off"
        },
        "paymentUnreachable": {
          "description": "Payment service is unavailable",
          "state": "ENABLED",
          "variants": {
            "on": true,
            "off": false
          },
          "defaultVariant": "off"
        },
        "loadGeneratorFloodHomepage": {
          "description": "Flood the frontend with a large amount of requests.",
          "state": "ENABLED",
          "variants": {
            "on": 100,
            "off": 0
          },
          "defaultVariant": "off"
        },
        "imageSlowLoad": {
          "description": "slow loading images in the frontend",
          "state": "ENABLED",
          "variants": {
            "10sec": 10000,
            "5sec": 5000,
            "off": 0
          },
          "defaultVariant": "off"
        }
      }
    }
---
# Source: opentelemetry-demo/templates/product-catalog-products.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: product-catalog-products
  #namespace: otel-demo
  labels:
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
data:
  products.json: |
    {
      "products": [
        {
          "id": "OLJCESPC7Z",
          "name": "National Park Foundation Explorascope",
          "description": "The National Park Foundation’s (NPF) Explorascope 60AZ is a manual alt-azimuth, refractor telescope perfect for celestial viewing on the go. The NPF Explorascope 60 can view the planets, moon, star clusters and brighter deep sky objects like the Orion Nebula and Andromeda Galaxy.",
          "picture": "NationalParkFoundationExplorascope.jpg",
          "priceUsd": {
            "currencyCode": "USD",
            "units": 101,
            "nanos": 960000000
          },
          "categories": [
            "telescopes"
          ]
        },
        {
          "id": "66VCHSJNUP",
          "name": "Starsense Explorer Refractor Telescope",
          "description": "The first telescope that uses your smartphone to analyze the night sky and calculate its position in real time. StarSense Explorer is ideal for beginners thanks to the app’s user-friendly interface and detailed tutorials. It’s like having your own personal tour guide of the night sky",
          "picture": "StarsenseExplorer.jpg",
          "priceUsd": {
            "currencyCode": "USD",
            "units": 349,
            "nanos": 950000000
          },
          "categories": [
            "telescopes"
          ]
        },
        {
          "id": "1YMWWN1N4O",
          "name": "Eclipsmart Travel Refractor Telescope",
          "description": "Dedicated white-light solar scope for the observer on the go. The 50mm refracting solar scope uses Solar Safe, ISO compliant, full-aperture glass filter material to ensure the safest view of solar events.  The kit comes complete with everything you need, including the dedicated travel solar scope, a Solar Safe finderscope, tripod, a high quality 20mm (18x) Kellner eyepiece and a nylon backpack to carry everything in.  This Travel Solar Scope makes it easy to share the Sun as well as partial and total solar eclipses with the whole family and offers much higher magnifications than you would otherwise get using handheld solar viewers or binoculars.",
          "picture": "EclipsmartTravelRefractorTelescope.jpg",
          "priceUsd": {
            "currencyCode": "USD",
            "units": 129,
            "nanos": 950000000
          },
          "categories": [
            "telescopes",
            "travel"
          ]
        },
        {
          "id": "L9ECAV7KIM",
          "name": "Lens Cleaning Kit",
          "description": "Wipe away dust, dirt, fingerprints and other particles on your lenses to see clearly with the Lens Cleaning Kit. This cleaning kit works on all glass and optical surfaces, including telescopes, binoculars, spotting scopes, monoculars, microscopes, and even your camera lenses, computer screens, and mobile devices.  The kit comes complete with a retractable lens brush to remove dust particles and dirt and two options to clean smudges and fingerprints off of your optics, pre-moistened lens wipes and a bottled lens cleaning fluid with soft cloth.",
          "picture": "LensCleaningKit.jpg",
          "priceUsd": {
            "currencyCode": "USD",
            "units": 21,
            "nanos": 950000000
          },
          "categories": [
            "accessories"
          ]
        },
        {
          "id": "2ZYFJ3GM2N",
          "name": "Roof Binoculars",
          "description": "This versatile, all-around binocular is a great choice for the trail, the stadium, the arena, or just about anywhere you want a close-up view of the action without sacrificing brightness or detail. It’s an especially great companion for nature observation and bird watching, with ED glass that helps you spot the subtlest field markings and a close focus of just 6.5 feet.",
          "picture": "RoofBinoculars.jpg",
          "priceUsd": {
            "currencyCode": "USD",
            "units": 209,
            "nanos": 950000000
          },
          "categories": [
            "binoculars"
          ]
        },
        {
          "id": "0PUK6V6EV0",
          "name": "Solar System Color Imager",
          "description": "You have your new telescope and have observed Saturn and Jupiter. Now you're ready to take the next step and start imaging them. But where do you begin? The NexImage 10 Solar System Imager is the perfect solution.",
          "picture": "SolarSystemColorImager.jpg",
          "priceUsd": {
            "currencyCode": "USD",
            "units": 175,
            "nanos": 0
          },
          "categories": [
            "accessories",
            "telescopes"
          ]
        },
        {
          "id": "LS4PSXUNUM",
          "name": "Red Flashlight",
          "description": "This 3-in-1 device features a 3-mode red flashlight, a hand warmer, and a portable power bank for recharging your personal electronics on the go. Whether you use it to light the way at an astronomy star party, a night walk, or wildlife research, ThermoTorch 3 Astro Red’s rugged, IPX4-rated design will withstand your everyday activities.",
          "picture": "RedFlashlight.jpg",
          "priceUsd": {
            "currencyCode": "USD",
            "units": 57,
            "nanos": 80000000
          },
          "categories": [
            "accessories",
            "flashlights"
          ]
        },
        {
          "id": "9SIQT8TOJO",
          "name": "Optical Tube Assembly",
          "description": "Capturing impressive deep-sky astroimages is easier than ever with Rowe-Ackermann Schmidt Astrograph (RASA) V2, the perfect companion to today’s top DSLR or astronomical CCD cameras. This fast, wide-field f/2.2 system allows for shorter exposure times compared to traditional f/10 astroimaging, without sacrificing resolution. Because shorter sub-exposure times are possible, your equatorial mount won’t need to accurately track over extended periods. The short focal length also lessens equatorial tracking demands. In many cases, autoguiding will not be required.",
          "picture": "OpticalTubeAssembly.jpg",
          "priceUsd": {
            "currencyCode": "USD",
            "units": 3599,
            "nanos": 0
          },
          "categories": [
            "accessories",
            "telescopes",
            "assembly"
          ]
        },
        {
          "id": "6E92ZMYYFZ",
          "name": "Solar Filter",
          "description": "Enhance your viewing experience with EclipSmart Solar Filter for 8” telescopes. With two Velcro straps and four self-adhesive Velcro pads for added safety, you can be assured that the solar filter cannot be accidentally knocked off and will provide Solar Safe, ISO compliant viewing.",
          "picture": "SolarFilter.jpg",
          "priceUsd": {
            "currencyCode": "USD",
            "units": 69,
            "nanos": 950000000
          },
          "categories": [
            "accessories",
            "telescopes"
          ]
        },
        {
          "id": "HQTGWGPNH4",
          "name": "The Comet Book",
          "description": "A 16th-century treatise on comets, created anonymously in Flanders (now northern France) and now held at the Universitätsbibliothek Kassel. Commonly known as The Comet Book (or Kometenbuch in German), its full title translates as “Comets and their General and Particular Meanings, According to Ptolomeé, Albumasar, Haly, Aliquind and other Astrologers”. The image is from https://publicdomainreview.org/collection/the-comet-book, made available by the Universitätsbibliothek Kassel under a CC-BY SA 4.0 license (https://creativecommons.org/licenses/by-sa/4.0/)",
          "picture": "TheCometBook.jpg",
          "priceUsd": {
            "currencyCode": "USD",
            "units": 0,
            "nanos": 990000000
          },
          "categories": [
            "books"
          ]
        }
      ]
    }
---
# Source: k8s-manifests/sql-server-express.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: sql
---
apiVersion: v1
kind: Secret
metadata:
  name: mssql-secrets
  namespace: sql
type: Opaque
stringData:
  SA_PASSWORD: "ChangeMe_SuperStrong123!"
  # Optional: full connection string if you want to inject as a single env var.
  DB_CONNECTION_STRING: "Server=tcp:sql-server-fraud.sql.svc.cluster.local,1433;Database=FraudDetection;User Id=sa;Password=ChangeMe_SuperStrong123!;Encrypt=True;TrustServerCertificate=True"
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: mssql-init-script
  namespace: sql
data:
  init-db.sql: |
    IF NOT EXISTS (SELECT name FROM sys.databases WHERE name = 'FraudDetection')
    BEGIN
      CREATE DATABASE FraudDetection;
    END
    GO
---
apiVersion: v1
kind: Service
metadata:
  name: sql-server-fraud
  namespace: sql
spec:
  type: ClusterIP
  ports:
    - port: 1433
      targetPort: 1433
      protocol: TCP
      name: tds
  selector:
    app: sql-server-fraud
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: sql-server-fraud
  namespace: sql
spec:
  serviceName: sql-server-fraud
  replicas: 1
  persistentVolumeClaimRetentionPolicy:
    whenDeleted: Delete
    whenScaled: Delete
  selector:
    matchLabels:
      app: sql-server-fraud
  template:
    metadata:
      labels:
        app: sql-server-fraud
    spec:
      containers:
        - name: mssql
          image: mcr.microsoft.com/mssql/server:2022-latest
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 1433
              name: tds
          env:
            - name: ACCEPT_EULA
              value: "Y"
            - name: MSSQL_PID
              value: "Express"
            - name: SA_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: mssql-secrets
                  key: SA_PASSWORD
          volumeMounts:
            - name: data
              mountPath: /var/opt/mssql
            - name: init-script
              mountPath: /docker-entrypoint-initdb.d
          lifecycle:
            postStart:
              exec:
                command:
                  - /bin/bash
                  - -c
                  - |
                    sleep 30
                    /opt/mssql-tools18/bin/sqlcmd -S localhost -U sa -P "${SA_PASSWORD}" -C -i /docker-entrypoint-initdb.d/init-db.sql
          resources:
            requests:
              cpu: "250m"
              memory: "1Gi"
            limits:
              cpu: "1"
              memory: "2Gi"
          readinessProbe:
            tcpSocket:
              port: 1433
            initialDelaySeconds: 10
            periodSeconds: 10
          livenessProbe:
            tcpSocket:
              port: 1433
            initialDelaySeconds: 30
            periodSeconds: 20
      volumes:
        - name: init-script
          configMap:
            name: mssql-init-script
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
            requests:
              storage: 5Gi
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: ad
  labels:
    opentelemetry.io/name: ad 
    app.kubernetes.io/component: ad
    app.kubernetes.io/name: ad
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:  
    opentelemetry.io/name: ad
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: cart
  labels:
    opentelemetry.io/name: cart 
    app.kubernetes.io/component: cart
    app.kubernetes.io/name: cart
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector: 
    opentelemetry.io/name: cart
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: checkout
  labels:  
    opentelemetry.io/name: checkout    
    app.kubernetes.io/component: checkout
    app.kubernetes.io/name: checkout
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    
    opentelemetry.io/name: checkout
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: currency
  labels:
    opentelemetry.io/name: currency  
    app.kubernetes.io/component: currency
    app.kubernetes.io/name: currency
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:  
    opentelemetry.io/name: currency
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: email
  labels:
    
    opentelemetry.io/name: email
    
    app.kubernetes.io/component: email
    app.kubernetes.io/name: email
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    opentelemetry.io/name: email
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: flagd
  labels:  
    opentelemetry.io/name: flagd   
    app.kubernetes.io/component: flagd
    app.kubernetes.io/name: flagd
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8013
      name: rpc
      targetPort: 8013
    - port: 8016
      name: ofrep
      targetPort: 8016
    - port: 4000
      name: tcp-service-0
      targetPort: 4000
  selector: 
    opentelemetry.io/name: flagd
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels: 
    opentelemetry.io/name: frontend 
    app.kubernetes.io/component: frontend
    app.kubernetes.io/name: frontend
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    opentelemetry.io/name: frontend
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: frontend-proxy
  labels:    
    opentelemetry.io/name: frontend-proxy   
    app.kubernetes.io/component: frontend-proxy
    app.kubernetes.io/name: frontend-proxy
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:  
    opentelemetry.io/name: frontend-proxy
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: image-provider
  labels:   
    opentelemetry.io/name: image-provider    
    app.kubernetes.io/component: image-provider
    app.kubernetes.io/name: image-provider
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8081
      name: tcp-service
      targetPort: 8081
  selector:  
    opentelemetry.io/name: image-provider
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: kafka
  labels:   
    opentelemetry.io/name: kafka    
    app.kubernetes.io/component: kafka
    app.kubernetes.io/name: kafka
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 9092
      name: plaintext
      targetPort: 9092
    - port: 9093
      name: controller
      targetPort: 9093
  selector:   
    opentelemetry.io/name: kafka
---
# # Source: opentelemetry-demo/templates/component.yaml
# apiVersion: v1
# kind: Service
# metadata:
#   name: load-generator
#   labels:
#     opentelemetry.io/name: load-generator 
#     app.kubernetes.io/component: load-generator
#     app.kubernetes.io/name: load-generator
#     app.kubernetes.io/version: "2.1.3"
#     app.kubernetes.io/part-of: opentelemetry-demo
# spec:
#   type: ClusterIP
#   ports:
#     - port: 8089
#       name: tcp-service
#       targetPort: 8089
#   selector:   
#    opentelemetry.io/name: load-generator
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: payment
  labels:   
    opentelemetry.io/name: payment    
    app.kubernetes.io/component: payment
    app.kubernetes.io/name: payment
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:    
    opentelemetry.io/name: payment
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: postgresql
  labels:    
    opentelemetry.io/name: postgresql    
    app.kubernetes.io/component: postgresql
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 5432
      name: tcp-service
      targetPort: 5432
  selector:   
    opentelemetry.io/name: postgresql
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: product-catalog
  labels:    
    opentelemetry.io/name: product-catalog 
    app.kubernetes.io/component: product-catalog
    app.kubernetes.io/name: product-catalog
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:   
    opentelemetry.io/name: product-catalog
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: quote
  labels:  
    opentelemetry.io/name: quote 
    app.kubernetes.io/component: quote
    app.kubernetes.io/name: quote
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    opentelemetry.io/name: quote
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: recommendation
  labels:
    opentelemetry.io/name: recommendation 
    app.kubernetes.io/component: recommendation
    app.kubernetes.io/name: recommendation
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    opentelemetry.io/name: recommendation
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: shipping
  labels:  
    opentelemetry.io/name: shipping
    app.kubernetes.io/component: shipping
    app.kubernetes.io/name: shipping
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector: 
    opentelemetry.io/name: shipping
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: valkey-cart
  labels:  
    opentelemetry.io/name: valkey-cart 
    app.kubernetes.io/component: valkey-cart
    app.kubernetes.io/name: valkey-cart
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 6379
      name: valkey-cart
      targetPort: 6379
  selector: 
    opentelemetry.io/name: valkey-cart
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: accounting
  labels:  
    opentelemetry.io/name: accounting   
    app.kubernetes.io/component: accounting
    app.kubernetes.io/name: accounting
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:    
      opentelemetry.io/name: accounting
  template:
    metadata:
      labels:        
        opentelemetry.io/name: accounting      
        app.kubernetes.io/component: accounting
        app.kubernetes.io/name: accounting
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: accounting
          #image: 'ghcr.io/open-telemetry/demo:2.1.3-accounting'
          image: 'ghcr.io/splunk/opentelemetry-demo/otel-accounting:2.1.3'
          imagePullPolicy: Always
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: OTEL_COLLECTOR_NAME
              value: $(NODE_IP)
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: KAFKA_ADDR
              value: kafka:9092
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://$(OTEL_COLLECTOR_NAME):4318
            - name: DB_CONNECTION_STRING
              value: Host=postgresql;Username=otelu;Password=otelp;Database=otel
            - name: OTEL_DOTNET_AUTO_TRACES_ENTITYFRAMEWORKCORE_INSTRUMENTATION_ENABLED
              value: "false"
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.1.3,service.kafka=spanlink
            - name: SPLUNK_PROFILER_ENABLED
              value: 'true'
            - name: SPLUNK_PROFILER_MEMORY_ENABLED
              value: 'true'
          resources:
            limits:
              memory: 300Mi
          volumeMounts:
      initContainers:
        - command:
          - sh
          - -c
          - until nc -z -v -w30 kafka 9092; do echo waiting for kafka; sleep 2; done;
          image: busybox:latest
          name: wait-for-kafka
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ad
  labels:  
    opentelemetry.io/name: ad    
    app.kubernetes.io/component: ad
    app.kubernetes.io/name: ad
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:     
      opentelemetry.io/name: ad
  template:
    metadata:
      labels:       
        opentelemetry.io/name: ad       
        app.kubernetes.io/component: ad
        app.kubernetes.io/name: ad
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: ad
          #image: 'ghcr.io/open-telemetry/demo:2.1.3-ad'
          image: ghcr.io/splunk/opentelemetry-demo/otel-ad:2.1.3
          imagePullPolicy: Always
          ports:            
            - containerPort: 8080
              name: service
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: OTEL_COLLECTOR_NAME
              value: $(NODE_IP)
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: AD_PORT
              value: "8080"
            - name: FLAGD_HOST
              value: flagd
            - name: FLAGD_PORT
              value: "8013"
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://$(OTEL_COLLECTOR_NAME):4318
            - name: OTEL_LOGS_EXPORTER
              value: otlp
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.1.3,service.kafka=no
            - name: SPLUNK_PROFILER_ENABLED
              value: "true"
            - name: SPLUNK_PROFILER_MEMORY_ENABLED
              value: "true"
            - name: SPLUNK_METRICS_ENABLED
              value: "true"
            - name: SPLUNK_SNAPSHOT_PROFILE_ENABLED
              value: "true"
            - name: SPLUNK_SNAPSHOT_SELECTION_PROBABILITY 
              value: "0.1"
            - name: OTEL_TRACE_EXPORTER
              value: otlp
            - name: OTEL_TRACES_SAMPLER
              value: "rules"
            #- name: OTEL_TRACES_SAMPLER_ARG
            #  value: "drop=/grpc.health.v1.Health;fallback=parentbased_always_on"    
            - name: SPLUNK_PROFILER_CALL_STACK_INTERVAL
              value: "500"
            - name: JAVA_TOOL_OPTIONS
              #  value: "-javaagent:/usr/src/app/splunk-otel-javaagent.jar -Dsplunk.profiler.include.internal.stacks=false -Dsplunk.profiler.cpu.data.format=pprof-gzip-base64 -Xmx640m"
              value: "-javaagent:/usr/src/app/splunk-otel-javaagent.jar"
          resources:
            limits:
              memory: 600Mi
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cart
  labels: 
    opentelemetry.io/name: cart
    app.kubernetes.io/component: cart
    app.kubernetes.io/name: cart
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:      
      opentelemetry.io/name: cart
  template:
    metadata:
      labels:        
        opentelemetry.io/name: cart        
        app.kubernetes.io/component: cart
        app.kubernetes.io/name: cart
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: cart
          #image: 'ghcr.io/open-telemetry/demo:2.1.3-cart'
          image: 'ghcr.io/splunk/opentelemetry-demo/otel-cart:2.1.3'
          imagePullPolicy: Always
          ports:          
            - containerPort: 8080
              name: service
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: OTEL_COLLECTOR_NAME
              value: $(NODE_IP)
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: CART_PORT
              value: "8080"
            - name: ASPNETCORE_URLS
              value: http://*:$(CART_PORT)
            - name: VALKEY_ADDR
              value: valkey-cart:6379
            - name: FLAGD_HOST
              value: flagd
            - name: FLAGD_PORT
              value: "8013"
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://$(OTEL_COLLECTOR_NAME):4317
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.1.3,service.kafka=no
            - name: OTEL_LOGS_EXPORTER
              value: otlp
            - name: SPLUNK_PROFILER_ENABLED
              value: "true"
            - name: SPLUNK_PROFILER_MEMORY_ENABLED
              value: "true"
          resources:
            limits:
              memory: 320Mi
          volumeMounts:
      initContainers:
        - command:
          - sh
          - -c
          - until nc -z -v -w30 valkey-cart 6379; do echo waiting for valkey-cart; sleep 2;
            done;
          image: busybox:latest
          name: wait-for-valkey-cart
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: checkout
  labels:    
    opentelemetry.io/name: checkout    
    app.kubernetes.io/component: checkout
    app.kubernetes.io/name: checkout
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:      
      opentelemetry.io/name: checkout
  template:
    metadata:
      labels:        
        opentelemetry.io/name: checkout        
        app.kubernetes.io/component: checkout
        app.kubernetes.io/name: checkout
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: checkout
          image: 'ghcr.io/open-telemetry/demo:2.1.3-checkout'
          imagePullPolicy: IfNotPresent
          ports:            
            - containerPort: 8080
              name: service
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: NODE_IP
              valueFrom:
                 fieldRef:
                  fieldPath: status.hostIP
            - name: OTEL_COLLECTOR_NAME
              value: $(NODE_IP)
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: CHECKOUT_PORT
              value: "8080"
            - name: CART_ADDR
              value: cart:8080
            - name: CURRENCY_ADDR
              value: currency:8080
            - name: EMAIL_ADDR
              value: http://email:8080
            - name: PAYMENT_ADDR
              value: payment:8080
            - name: PRODUCT_CATALOG_ADDR
              value: product-catalog:8080
            - name: SHIPPING_ADDR
              value: http://shipping:8080
            - name: KAFKA_ADDR
              value: kafka:9092
            - name: FLAGD_HOST
              value: flagd
            - name: FLAGD_PORT
              value: "8013"
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://$(OTEL_COLLECTOR_NAME):4317
            - name: GOMEMLIMIT
              value: 16MiB
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.1.3,service.kafka=no
          resources:
            limits:
              memory: 20Mi
          volumeMounts:
      initContainers:
        - command:
          - sh
          - -c
          - until nc -z -v -w30 kafka 9092; do echo waiting for kafka; sleep 2; done;
          image: busybox:latest
          name: wait-for-kafka
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: currency
  labels:    
    opentelemetry.io/name: currency    
    app.kubernetes.io/component: currency
    app.kubernetes.io/name: currency
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:     
      opentelemetry.io/name: currency
  template:
    metadata:
      labels:       
        opentelemetry.io/name: currency       
        app.kubernetes.io/component: currency
        app.kubernetes.io/name: currency
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: currency
          image: 'ghcr.io/open-telemetry/demo:2.1.3-currency'
          imagePullPolicy: IfNotPresent
          ports:            
            - containerPort: 8080
              name: service
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: NODE_IP
              valueFrom:
                 fieldRef:
                  fieldPath: status.hostIP
            - name: OTEL_COLLECTOR_NAME
              value: $(NODE_IP)
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: CURRENCY_PORT
              value: "8080"
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://$(OTEL_COLLECTOR_NAME):4317
            - name: VERSION
              value: '2.1.3'
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.1.3,service.kafka=no
          resources:
            limits:
              memory: 20Mi
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: email
  labels:    
    opentelemetry.io/name: email    
    app.kubernetes.io/component: email
    app.kubernetes.io/name: email
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:      
      opentelemetry.io/name: email
  template:
    metadata:
      labels:       
        opentelemetry.io/name: email       
        app.kubernetes.io/component: email
        app.kubernetes.io/name: email
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: email
          image: 'ghcr.io/open-telemetry/demo:2.1.3-email'
          imagePullPolicy: IfNotPresent
          ports:            
            - containerPort: 8080
              name: service
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: NODE_IP
              valueFrom:
                 fieldRef:
                  fieldPath: status.hostIP
            - name: OTEL_COLLECTOR_NAME
              value: $(NODE_IP)
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: EMAIL_PORT
              value: "8080"
            - name: APP_ENV
              value: production
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://$(OTEL_COLLECTOR_NAME):4318
            - name: FLAGD_HOST
              value: flagd
            - name: FLAGD_PORT
              value: "8013"
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.1.3,service.kafka=no
          resources:
            limits:
              memory: 100Mi
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: flagd
  labels:    
    opentelemetry.io/name: flagd    
    app.kubernetes.io/component: flagd
    app.kubernetes.io/name: flagd
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:    
      opentelemetry.io/name: flagd
  template:
    metadata:
      labels:        
        opentelemetry.io/name: flagd        
        app.kubernetes.io/component: flagd
        app.kubernetes.io/name: flagd
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: flagd
          image: 'ghcr.io/open-feature/flagd:v0.12.8'
          imagePullPolicy: IfNotPresent
          command:
            - /flagd-build
            - start
            - --port
            - "8013"
            - --ofrep-port
            - "8016"
            - --uri
            - file:./etc/flagd/demo.flagd.json
          ports:          
            - containerPort: 8013
              name: rpc
            - containerPort: 8016
              name: ofrep
          env:
            # - name: OTEL_SERVICE_NAME
            #   valueFrom:
            #     fieldRef:
            #       apiVersion: v1
            #       fieldPath: metadata.labels['app.kubernetes.io/component']
            # - name: OTEL_COLLECTOR_NAME
            #   value: otel-collector
            # - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            #   value: cumulative
            # - name: FLAGD_METRICS_EXPORTER
            #   value: otel
            # - name: FLAGD_OTEL_COLLECTOR_URI
            #   value: $(OTEL_COLLECTOR_NAME):4317
            # - name: OTEL_RESOURCE_ATTRIBUTES
            #   value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.1.3
             - name: GOMEMLIMIT
               value: 60MiB
          resources:
            limits:
              memory: 75Mi
          volumeMounts:
            - name: config-rw
              mountPath: /etc/flagd
        - name: flagd-ui
          image: 'ghcr.io/open-telemetry/demo:2.1.3-flagd-ui'
          imagePullPolicy: IfNotPresent
          ports:   
            - containerPort: 4000
              name: service
          env:
            #- name: OTEL_PROPAGATORS  # Disables trace output with none
            #  value: "none" 
            # - name: OTEL_SERVICE_NAME
            #   valueFrom:
            #     fieldRef:
            #       apiVersion: v1
            #       fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: NODE_IP
              valueFrom:
                 fieldRef:
                  fieldPath: status.hostIP
            - name: OTEL_COLLECTOR_NAME
              value: $(NODE_IP)
            # - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            #   value: cumulative
            # - name: FLAGD_METRICS_EXPORTER
            #   value: otel
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://$(OTEL_COLLECTOR_NAME):4318
            - name: FLAGD_UI_PORT
              value: "4000"
            - name: SECRET_KEY_BASE
              value: yYrECL4qbNwleYInGJYvVnSkwJuSQJ4ijPTx5tirGUXrbznFIBFVJdPl5t6O9ASw
            - name: PHX_HOST
              value: localhost
            # - name: OTEL_RESOURCE_ATTRIBUTES
            #   value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.1.3
          resources:
            limits:
              memory: 250Mi
          volumeMounts:
            - mountPath: /app/data
              name: config-rw
      initContainers:
        - command:
          - sh
          - -c
          - cp /config-ro/demo.flagd.json /config-rw/demo.flagd.json && cat /config-rw/demo.flagd.json
          image: busybox
          name: init-config
          volumeMounts:
          - mountPath: /config-ro
            name: config-ro
          - mountPath: /config-rw
            name: config-rw
      volumes:
        - name: config-rw
          emptyDir: {}
        - configMap:
            name: flagd-config
          name: config-ro
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: fraud-detection
  labels: 
    opentelemetry.io/name: fraud-detection    
    app.kubernetes.io/component: fraud-detection
    app.kubernetes.io/name: fraud-detection
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:      
      opentelemetry.io/name: fraud-detection
  template:
    metadata:
      labels:       
        opentelemetry.io/name: fraud-detection       
        app.kubernetes.io/component: fraud-detection
        app.kubernetes.io/name: fraud-detection
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: fraud-detection
          #image: 'ghcr.io/open-telemetry/demo:2.1.3-fraud-detection'
          image: ghcr.io/splunk/opentelemetry-demo/otel-fraud-detection:2.1.3-for-jeremy
          imagePullPolicy: Always
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: OTEL_COLLECTOR_NAME
              value: $(NODE_IP)
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: KAFKA_ADDR
              value: kafka:9092
            - name: FLAGD_HOST
              value: flagd
            - name: FLAGD_PORT
              value: "8013"
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://$(OTEL_COLLECTOR_NAME):4318
            - name: OTEL_INSTRUMENTATION_KAFKA_EXPERIMENTAL_SPAN_ATTRIBUTES
              value: "true"
            - name: OTEL_INSTRUMENTATION_MESSAGING_EXPERIMENTAL_RECEIVE_TELEMETRY_ENABLED
              value: "true"
            - name: OTEL_INSTRUMENTATION_SPLUNK_JDBC_ENABLED  
              value: "true"
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.1.3,service.kafka=spanlink
            - name: SQL_SERVER_HOST
              value: sql-server-fraud.sql.svc.cluster.local
            - name: SQL_SERVER_PORT
              value: "1433"
            - name: SQL_SERVER_DATABASE
              value: FraudDetection
            - name: SQL_SERVER_USER
              value: sa
            - name: SQL_SERVER_PASSWORD
              value: "ChangeMe_SuperStrong123!"
            - name: FRAUD_DETECTION_RATE
              value: "80"          
            - name: CLEANUP_RETENTION_DAYS
              value: "7"
            - name: CLEANUP_INTERVAL_HOURS
              value: "24"
            - name: FRAUD_MUTATION_PERCENTAGE 
              value: "25"
            - name: BAD_QUERY_PERCENTAGE
              value: "0"   
          resources:
            limits:
              memory: 450Mi
          volumeMounts:
      initContainers:
        - command:
          - sh
          - -c
          - until nc -z -v -w30 kafka 9092; do echo waiting for kafka; sleep 2; done;
          image: busybox:latest
          name: wait-for-kafka
        - command:
          - sh
          - -c
          - until nc -z -v -w30 sql-server-fraud.sql.svc.cluster.local 1433; do echo waiting for sql-server-fraud; sleep 2; done;
          image: busybox:latest
          name: wait-for-sqlserver
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
  labels:   
    opentelemetry.io/name: frontend   
    app.kubernetes.io/component: frontend
    app.kubernetes.io/name: frontend
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:     
      opentelemetry.io/name: frontend
  template:
    metadata:
      labels:      
        opentelemetry.io/name: frontend    
        app.kubernetes.io/component: frontend
        app.kubernetes.io/name: frontend
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: frontend
          #image: 'ghcr.io/open-telemetry/demo:2.1.3-frontend'
          image: ghcr.io/splunk/opentelemetry-demo/otel-frontend:2.1.3
          imagePullPolicy: Always
          ports:        
            - containerPort: 8080
              name: service
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: OTEL_COLLECTOR_NAME
              value: $(NODE_IP)
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: FRONTEND_PORT
              value: "8080"
            - name: PORT
              value: $(FRONTEND_PORT)
            - name: FRONTEND_ADDR
              value: :8080
            - name: AD_ADDR
              value: ad:8080
            - name: CART_ADDR
              value: cart:8080
            - name: CHECKOUT_ADDR
              value: checkout:8080
            - name: CURRENCY_ADDR
              value: currency:8080
            - name: PRODUCT_CATALOG_ADDR
              value: product-catalog:8080
            - name: RECOMMENDATION_ADDR
              value: recommendation:8080
            - name: SHIPPING_ADDR
              value: http://shipping:8080
            - name: FLAGD_HOST
              value: flagd
            - name: FLAGD_PORT
              value: "8013"
            - name: ENV_PLATFORM
              value: kubernetes
            - name: OTEL_COLLECTOR_HOST
              value: $(OTEL_COLLECTOR_NAME)
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://$(OTEL_COLLECTOR_NAME):4317
            # - name: WEB_OTEL_SERVICE_NAME
            #   value: frontend-web
            # - name: PUBLIC_OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
            #   value: http://localhost:8080/otlp-http/v1/traces
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.1.3,service.kafka=no
            - name: SPLUNK_RUM_TOKEN
              valueFrom:
                secretKeyRef:
                  name: workshop-secret
                  key: rum_token
            - name: SPLUNK_APP_NAME
              valueFrom:
                secretKeyRef:
                  name: workshop-secret
                  key: app
            - name: SPLUNK_RUM_ENV
              valueFrom:
                secretKeyRef:
                  name: workshop-secret
                  key: env
            - name: SPLUNK_RUM_REALM
              valueFrom:
                secretKeyRef:
                  name: workshop-secret
                  key: realm
          resources:
            limits:
              memory: 250Mi
          securityContext:
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend-proxy
  labels:   
    opentelemetry.io/name: frontend-proxy    
    app.kubernetes.io/component: frontend-proxy
    app.kubernetes.io/name: frontend-proxy
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:    
      opentelemetry.io/name: frontend-proxy
  template:
    metadata:
      labels:        
        opentelemetry.io/name: frontend-proxy       
        app.kubernetes.io/component: frontend-proxy
        app.kubernetes.io/name: frontend-proxy
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: frontend-proxy
          #image: 'ghcr.io/open-telemetry/demo:2.1.3-frontend-proxy'
          image:  ghcr.io/splunk/opentelemetry-demo/otel-frontend-proxy:2.1.3
          imagePullPolicy: Always
          ports:            
            - containerPort: 8080
              name: service
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: OTEL_COLLECTOR_NAME
              value: $(NODE_IP)
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: ENVOY_PORT
              value: "8080"
            - name: ENVOY_ADMIN_PORT
              value: "10000"
            - name: FLAGD_HOST
              value: flagd
            - name: FLAGD_PORT
              value: "8013"
            - name: FLAGD_UI_HOST
              value: flagd
            - name: FLAGD_UI_PORT
              value: "4000"
            - name: FRONTEND_HOST
              value: frontend
            - name: FRONTEND_PORT
              value: "8080"
            - name: IMAGE_PROVIDER_HOST
              value: image-provider
            - name: IMAGE_PROVIDER_PORT
              value: "8081"
            - name: LOCUST_WEB_HOST
              value: load-generator
            - name: LOCUST_WEB_PORT
              value: "8089"
            - name: OTEL_COLLECTOR_HOST
              value: $(OTEL_COLLECTOR_NAME)
            - name: OTEL_COLLECTOR_PORT_GRPC
              value: "4317"
            - name: OTEL_COLLECTOR_PORT_HTTP
              value: "4318"
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.1.3,service.kafka=no
            - name: FEATURE_AUTH_ENABLED
              value: "true"     # enables auth for /feature
            - name: FEATURE_USER
              value: "Robert"
            - name: FEATURE_PASS
              value: "007"  
          resources:
            limits:
              memory: 65Mi
          securityContext:
            runAsGroup: 101
            runAsNonRoot: true
            runAsUser: 101
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: image-provider
  labels:    
    opentelemetry.io/name: image-provider  
    app.kubernetes.io/component: image-provider
    app.kubernetes.io/name: image-provider
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:     
      opentelemetry.io/name: image-provider
  template:
    metadata:
      labels:      
        opentelemetry.io/name: image-provider      
        app.kubernetes.io/component: image-provider
        app.kubernetes.io/name: image-provider
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: image-provider
          #image: 'ghcr.io/open-telemetry/demo:2.1.3-image-provider'
          image: 'ghcr.io/splunk/opentelemetry-demo/otel-image-provider:2.1.3'
          imagePullPolicy: IfNotPresent
          ports:    
            - containerPort: 8081
              name: service
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: NODE_IP
              valueFrom:
                 fieldRef:
                  fieldPath: status.hostIP
            - name: OTEL_COLLECTOR_NAME
              value: $(NODE_IP)
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: IMAGE_PROVIDER_PORT
              value: "8081"
            - name: OTEL_COLLECTOR_PORT_GRPC
              value: "4317"
            - name: OTEL_COLLECTOR_HOST
              value: $(OTEL_COLLECTOR_NAME)
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.1.3,service.kafka=no
          resources:
            limits:
              memory: 50Mi
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka
  labels:   
    opentelemetry.io/name: kafka    
    app.kubernetes.io/component: kafka
    app.kubernetes.io/name: kafka
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:     
      opentelemetry.io/name: kafka
  template:
    metadata:
      labels: 
        opentelemetry.io/name: kafka
        app.kubernetes.io/component: kafka
        app.kubernetes.io/name: kafka
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: kafka
          image: 'ghcr.io/open-telemetry/demo:2.1.3-kafka'
          imagePullPolicy: IfNotPresent
          ports:          
            - containerPort: 9092
              name: plaintext
            - containerPort: 9093
              name: controller
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: NODE_IP
              valueFrom:
                 fieldRef:
                  fieldPath: status.hostIP
            - name: OTEL_COLLECTOR_NAME
              value: $(NODE_IP)
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: KAFKA_ADVERTISED_LISTENERS
              value: PLAINTEXT://kafka:9092
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://$(OTEL_COLLECTOR_NAME):4318
            - name: KAFKA_HEAP_OPTS
              value: -Xmx400M -Xms400M
            - name: KAFKA_LISTENERS
              value: PLAINTEXT://:9092,CONTROLLER://:9093
            - name: KAFKA_CONTROLLER_LISTENER_NAMES
              value: CONTROLLER
            - name: KAFKA_CONTROLLER_QUORUM_VOTERS
              value: 1@kafka:9093
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.1.3,service.kafka=no
          resources:
            limits:
              memory: 800Mi
          securityContext:
            runAsGroup: 1000
            runAsNonRoot: true
            runAsUser: 1000
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: payment
  labels:    
    opentelemetry.io/name: payment   
    app.kubernetes.io/component: payment
    app.kubernetes.io/name: payment
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:      
      opentelemetry.io/name: payment
  template:
    metadata:
      labels:        
        opentelemetry.io/name: payment        
        app.kubernetes.io/component: payment
        app.kubernetes.io/name: payment
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: payment
          image: 'ghcr.io/open-telemetry/demo:2.1.3-payment'
          #image: ghcr.io/splunk/opentelemetry-demo/otel-payment:2.1.3-splunk
          imagePullPolicy: Always
          ports:        
            - containerPort: 8080
              name: service
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: NODE_IP
              valueFrom:
                 fieldRef:
                  fieldPath: status.hostIP
            - name: OTEL_COLLECTOR_NAME
              value: $(NODE_IP)
            # - name: OTEL_EXPORTER_OTLP_PROTOCOL
            #   value: grpc  
            # - name: OTEL_TRACES_EXPORTER
            #   value: otlp
            # - name: OTEL_METRICS_EXPORTER
            #   value: otlp
            - name: OTEL_LOGS_EXPORTER
              value: otlp
            - name: SPLUNK_OTEL_LOG_CORRELATION_ENABLED
              value: "true"  
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: PAYMENT_PORT
              value: "8080"
            - name: FLAGD_HOST
              value: flagd
            - name: FLAGD_PORT
              value: "8013"
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://$(NODE_IP):4317
            # - name: OTEL_EXPORTER_OTLP_METRICS_ENDPOINT
            #   value: http://$(NODE_IP):4317
            # - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
            #   value: http://$(NODE_IP):4317
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.1.3,service.kafka=no
            - name: OTEL_PROFILER_LOGS_ENDPOINT
              value: http://$(OTEL_COLLECTOR_NAME):4318
            - name: SPLUNK_PROFILER_CALL_STACK_INTERVAL
              value: "750"
            - name: SPLUNK_PROFILER_ENABLED
              value: "false"
            - name: SPLUNK_PROFILER_MEMORY_ENABLED
              value: "false"   
            - name: OTEL_LOG_LEVEL
              value: "info"  
          resources:
            limits:
              memory: 520Mi
          securityContext:
            runAsGroup: 1000
            runAsNonRoot: true
            runAsUser: 1000
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: postgresql
  labels:   
    opentelemetry.io/name: postgresql    
    app.kubernetes.io/component: postgresql
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:    
      opentelemetry.io/name: postgresql
  template:
    metadata:
      labels:       
        opentelemetry.io/name: postgresql     
        app.kubernetes.io/component: postgresql
        app.kubernetes.io/name: postgresql
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: postgresql
          image: 'ghcr.io/open-telemetry/demo:2.1.3-postgresql'
          imagePullPolicy: IfNotPresent
          ports:        
            - containerPort: 5432
              name: service
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: NODE_IP
              valueFrom:
                 fieldRef:
                  fieldPath: status.hostIP
            - name: OTEL_COLLECTOR_NAME
              value: $(NODE_IP)
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: POSTGRES_USER
              value: root
            - name: POSTGRES_PASSWORD
              value: otel
            - name: POSTGRES_DB
              value: otel
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.1.3,service.kafka=no
          resources:
            limits:
              memory: 100Mi
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: product-catalog
  labels:    
    opentelemetry.io/name: product-catalog
    app.kubernetes.io/component: product-catalog
    app.kubernetes.io/name: product-catalog
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:  
      opentelemetry.io/name: product-catalog
  template:
    metadata:
      labels:  
        opentelemetry.io/name: product-catalog  
        app.kubernetes.io/component: product-catalog
        app.kubernetes.io/name: product-catalog
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: product-catalog
          image: 'ghcr.io/open-telemetry/demo:2.1.3-product-catalog'
          imagePullPolicy: IfNotPresent
          ports:  
            - containerPort: 8080
              name: service
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: NODE_IP
              valueFrom:
                 fieldRef:
                  fieldPath: status.hostIP
            - name: OTEL_COLLECTOR_NAME
              value: $(NODE_IP) 
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: PRODUCT_CATALOG_PORT
              value: "8080"
            - name: PRODUCT_CATALOG_RELOAD_INTERVAL
              value: "10"
            - name: FLAGD_HOST
              value: flagd
            - name: FLAGD_PORT
              value: "8013"
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://$(OTEL_COLLECTOR_NAME):4317
            - name: GOMEMLIMIT
              value: 16MiB
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.1.3,service.kafka=no
          resources:
            limits:
              memory: 20Mi
          volumeMounts:
            - name: product-catalog-products
              mountPath: /usr/src/app/products
      volumes:
        - name: product-catalog-products
          configMap:
            name: product-catalog-products
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: quote
  labels: 
    opentelemetry.io/name: quote 
    app.kubernetes.io/component: quote
    app.kubernetes.io/name: quote
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels: 
      opentelemetry.io/name: quote
  template:
    metadata:
      labels:    
        opentelemetry.io/name: quote  
        app.kubernetes.io/component: quote
        app.kubernetes.io/name: quote
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: quote
          image: 'ghcr.io/open-telemetry/demo:2.1.3-quote'
          imagePullPolicy: IfNotPresent
          ports:           
            - containerPort: 8080
              name: service
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: NODE_IP
              valueFrom:
                 fieldRef:
                  fieldPath: status.hostIP
            - name: OTEL_COLLECTOR_NAME
              value: $(NODE_IP)
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: QUOTE_PORT
              value: "8080"
            - name: OTEL_PHP_AUTOLOAD_ENABLED
              value: "true"
            - name: OTEL_PHP_INTERNAL_METRICS_ENABLED
              value: "true"
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://$(OTEL_COLLECTOR_NAME):4318
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.1.3,service.kafka=no
          resources:
            limits:
              memory: 40Mi
          securityContext:
            runAsGroup: 33
            runAsNonRoot: true
            runAsUser: 33
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: recommendation
  labels:  
    opentelemetry.io/name: recommendation   
    app.kubernetes.io/component: recommendation
    app.kubernetes.io/name: recommendation
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:      
      opentelemetry.io/name: recommendation
  template:
    metadata:
      labels:        
        opentelemetry.io/name: recommendation       
        app.kubernetes.io/component: recommendation
        app.kubernetes.io/name: recommendation
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: recommendation
          #mage: 'ghcr.io/open-telemetry/demo:2.1.3-recommendation'
          image: ghcr.io/splunk/opentelemetry-demo/otel-recommendation:2.1.3
          imagePullPolicy: Always
          ports:            
            - containerPort: 8080
              name: service
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: NODE_IP
              valueFrom:
                 fieldRef:
                  fieldPath: status.hostIP
            - name: OTEL_COLLECTOR_NAME
              value: $(NODE_IP)
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: RECOMMENDATION_PORT
              value: "8080"
            - name: PRODUCT_CATALOG_ADDR
              value: product-catalog:8080
            - name: OTEL_PYTHON_LOG_CORRELATION
              value: "true"
            - name: PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION
              value: python
            - name: FLAGD_HOST
              value: flagd
            - name: FLAGD_PORT
              value: "8013"
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://$(OTEL_COLLECTOR_NAME):4317
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.1.3,service.kafka=no
            - name: OTEL_PROFILER_LOGS_ENDPOINT
              value: http://$(OTEL_COLLECTOR_NAME):4317
            - name: SPLUNK_PROFILER_CALL_STACK_INTERVAL
              value: "750"
            - name: SPLUNK_PROFILER_ENABLED
              value: "true"
          resources:
            limits:
              memory: 500Mi
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: shipping
  labels:  
    opentelemetry.io/name: shipping  
    app.kubernetes.io/component: shipping
    app.kubernetes.io/name: shipping
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:     
      opentelemetry.io/name: shipping
  template:
    metadata:
      labels:        
        opentelemetry.io/name: shipping       
        app.kubernetes.io/component: shipping
        app.kubernetes.io/name: shipping
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: shipping
          image: 'ghcr.io/open-telemetry/demo:2.1.3-shipping'
          imagePullPolicy: IfNotPresent
          ports:          
            - containerPort: 8080
              name: service
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: NODE_IP
              valueFrom:
                 fieldRef:
                  fieldPath: status.hostIP
            - name: OTEL_COLLECTOR_NAME
              value: $(NODE_IP) 
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: SHIPPING_PORT
              value: "8080"
            - name: QUOTE_ADDR
              value: http://quote:8080
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://$(OTEL_COLLECTOR_NAME):4317
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.1.3,service.kafka=no
          resources:
            limits:
              memory: 20Mi
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: valkey-cart
  labels:    
    opentelemetry.io/name: valkey-cart  
    app.kubernetes.io/component: valkey-cart
    app.kubernetes.io/name: valkey-cart
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:    
      opentelemetry.io/name: valkey-cart
  template:
    metadata:
      labels:       
        opentelemetry.io/name: valkey-cart        
        app.kubernetes.io/component: valkey-cart
        app.kubernetes.io/name: valkey-cart
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: valkey-cart
          image: 'valkey/valkey:8.1.3-alpine'
          imagePullPolicy: IfNotPresent
          ports:            
            - containerPort: 6379
              name: valkey-cart
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.labels['app.kubernetes.io/component']
            - name: NODE_IP
              valueFrom:
                 fieldRef:
                  fieldPath: status.hostIP
            - name: OTEL_COLLECTOR_NAME
              value: $(NODE_IP)
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.1.3,service.kafka=no
          resources:
            limits:
              memory: 20Mi
          securityContext:
            runAsGroup: 1000
            runAsNonRoot: true
            runAsUser: 999
          volumeMounts:
      volumes:
---
# ingress format for local demo
# apiVersion: networking.k8s.io/v1
# kind: Ingress
# metadata:
#   name: frontend-proxy-ingress
#  # annotations:
#  #   kubernetes.io/ingress.class: traefik
# spec:
#   rules:
#     - http:
#         paths:
#           - path: /
#             pathType: Prefix
#             backend:
#               service:
#                 name: frontend-proxy
#                 port:
#                   number: 8080
---
# Ingress format for official demo with AWS domain
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: frontend-proxy
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    traefik.ingress.kubernetes.io/router.middlewares: default-custom-headers@kubernetescrd
spec:
  ingressClassName: traefik
  tls:
  - hosts:
    - dev-astronomy.splunko11y.com
    secretName: splunk-demo-tls
  rules:
  - host: dev-astronomy.splunko11y.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: frontend-proxy
            port:
              number: 8080

apiVersion: apps/v1
kind: Deployment
metadata:
  name: astronomy-loadgen-deployment
  labels:
    app: astronomy-loadgen
spec:
  replicas: 1
  selector:
    matchLabels:
      app: astronomy-loadgen
  template:
    metadata:
      labels:
        app: astronomy-loadgen
    spec:
      # If you are NOT running this from AWS, but from multipass for example set the below env variable
      # set RUM_FRONTEND_IP to the IP address where you can reach your local Online Boutique
      #env:
      #  - name: RUM_FRONTEND_IP
      #    value: "192.168.1.99"
      containers:
        - name: astronomy-loadgen
          image: ghcr.io/splunk/online-boutique/rumloadgen:5.6
          imagePullPolicy: Always
          env:
            - name: RUM_FRONTEND_IP
              valueFrom:
                secretKeyRef:
                  name: workshop-secret
                  key: url
              #value:  192.168.3.214
          volumeMounts:
            - name: puppeteer
              subPath: local-file
              mountPath: /puppeteer/touchwebsite.js
      volumes:
        - name: puppeteer
          configMap:
            name: scriptfile
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: scriptfile
data:
  local-file: |
    /* eslint-disable no-console */
    const { Console } = require('console');
    const puppeteer = require('puppeteer');

    async function launchBrowser() {
      console.log('🔹 Starting headless browser...');
      const browser = await puppeteer.launch({
        headless: true,
        defaultViewport: null,
        args: [
          '--no-sandbox',
          '--disable-setuid-sandbox',
          '--disable-gpu',
          '--disable-dev-shm-usage',
          '--disable-web-security',
          '--disable-features=VizDisplayCompositor',
          '--max-old-space-size=256',
          '--disable-extensions',
          '--disable-plugins',
          '--disable-background-networking',
          '--disable-background-timer-throttling',
          '--disable-backgrounding-occluded-windows',
          '--disable-renderer-backgrounding',
          '--memory-pressure-off'
        ]
      });
      console.log('✅ Browser started.');
      return browser;
    }

    function buildBaseUrl() {
      const raw = (process.env.RUM_FRONTEND_IP || '').trim();

      // If it's empty, default to localhost
      if (!raw) return 'https://localhost/';

      // If it already starts with http:// or https://, keep it exactly as-is
      if (/^https?:\/\//i.test(raw)) {
        return raw.replace(/\/+$/, '') + '/';
      }

      // Otherwise, prepend https://
      return `https://${raw.replace(/\/+$/, '')}/`;
    }
    function delay(ms) { return new Promise(res => setTimeout(res, ms)); }

    /** Wait until innerText of the page contains a substring */
    async function waitForText(page, text, timeoutMs = 30000, pollMs = 200) {
      const start = Date.now();
      while (Date.now() - start < timeoutMs) {
        const found = await page.evaluate(t =>
          document && document.body && document.body.innerText.includes(t), text
        );
        if (found) return true;
        await delay(pollMs);
      }
      throw new Error(`Timed out waiting for text: "${text}"`);
    }

    async function runOnce() {
      const browser = await launchBrowser();
      let page;
      try {
        page = await browser.newPage();
        page.setDefaultNavigationTimeout(45000);
        page.setDefaultTimeout && page.setDefaultTimeout(30000);

        const base = buildBaseUrl();
        const url  = new URL('product/66VCHSJNUP', base).toString();

        console.log(`🌐 Navigating to ${url}`);
        await page.goto(url, { waitUntil: 'domcontentloaded' });

        const addSel = "[data-cy='product-add-to-cart']";
        await page.waitForSelector(addSel);
        console.log('🖱️ Clicking "Add To Cart"');
        await page.click(addSel);

        const placeSel = "[data-cy='checkout-place-order']";
        await page.waitForSelector(placeSel);
        console.log('🖱️ Clicking "Place Order"');
        await page.click(placeSel);

        await waitForText(page, 'Your order is complete!');
        console.log('🎉 Order completed message detected.');
      } finally {
        console.log('🧹 Closing browser...');
        try {
          if (page) {
            page.removeAllListeners();
            await page.close({ runBeforeUnload: true }).catch(()=>{});
          }
        } catch {}
        try {
          await browser.close();
        } catch (e) {
          // last-resort: nuke the child process if close() fails
          try { browser.process()?.kill('SIGKILL'); } catch {}
        }
        console.log('✅ Browser closed cleanly.');
      }
    }

    (async function mainLoop() {
      let cycle = 1;
      while (true) {
        console.log(`=== Starting load generation cycle #${cycle} ===`);
        try {
          await runOnce();
          console.log(`✅ Cycle #${cycle} finished OK`);
        } catch (e) {
          console.error(`❌ Cycle #${cycle} failed:`, e && e.stack ? e.stack : e);
        }
        cycle += 1;
        await delay(5000); // wait 5 seconds before next cycle
      }
    })();
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations: {}
  namespace: default
  name: thousandeyes
  labels:
    app: thousandeyes
spec:
  replicas: 1
  selector:
    matchLabels:
      app: thousandeyes
  template:
    metadata:
      labels:
        app: thousandeyes
    spec:
      hostname: dev-astronomy-shop
      containers:
       - name: thousandeyes
         image: 'thousandeyes/enterprise-agent:latest'
         imagePullPolicy: Always
         command:
          - /sbin/my_init
         securityContext:
           capabilities:
             add:
               - NET_ADMIN
               - SYS_ADMIN
         env:
           - name: TEAGENT_ACCOUNT_TOKEN
             valueFrom:
              secretKeyRef:
                name: te-creds
                key: TEAGENT_ACCOUNT_TOKEN
            # value: xyz
           - name: TEAGENT_INET
             value: "4"
         resources:
             limits:
               memory: 3584Mi
             requests:
               memory: 2000Mi
      restartPolicy: Always
